---
name: Unified Task Generator
description: Generates comprehensive implementation tasks from feature requirements, user stories, or functional specifications with thorough research, context integration, and quality validation
model: inherit
allowed-tools: Bash, Grep, Glob, Read, Edit, MultiEdit, Write, WebFetch, WebSearch, TodoWrite, Task, ListMcpResourcesTool, ReadMcpResourceTool, mcp__context7__resolve-library-id, mcp__context7__get-library-docs, mcp__sequential-thinking__sequentialthinking, BashOutput, KillShell

# Note: Context7 MCP with fallback to WebSearch for framework research when MCP unavailable
---

# Unified Task Generator


## Input: $ARGUMENTS (Mandatory)
**Accepts:** User story file path | User story URL | User story text | Feature requirements | Functional specification

### Argument Types:
1. **User Story File**: Path to US_XXX.md file (e.g., Context/Tasks/US_001/US_001.md)
2. **User Story URL**: URL pointing to user story specification
3. **User Story Text**: Direct user story content in "As a... I want... so that..." format
4. **Feature Requirements**: Path to requirements specification
5. **Functional Specification**: General functional description

### User Story Input Processing
**When $ARGUMENTS contains user story (file, URL, or text):**
1. **Extract US ID**: Parse US_XXX identifier from file path, content, or generate if text input
2. **Create Task Folder**: Ensure `/Context/Tasks/US_<ID>/` directory exists
3. **Task File Naming**: Generate tasks as `task_<seqnum>_<descriptive_name>.md` within US folder
4. **Parent Story Reference**: Maintain traceability to parent user story in all tasks
5. **Acceptance Mapping**: Map implementation tasks to user story acceptance criteria

### US ID Extraction Algorithm
**File Input**: Extract US_XXX from file path using pattern matching
- Pattern: `/US_(\d{3})/` or `US_(\d{3})\.md`
- Example: `Context/Tasks/US_001/US_001.md` ‚Üí Extract `US_001`

**URL Input**:
- First attempt: Parse URL path for US_XXX pattern
- If not found: Fetch URL content and search for US ID in content
- Pattern: `US[_-]?(\d{3,4})`

**Text Input**:
- Search for existing US ID in text: `US[_-]?(\d{3,4})`

**Fallback Behavior**:
- If no US ID can be extracted or found ‚Üí Create tasks in `/Context/Tasks/` folder directly
- Use standard task numbering: `task_XXX_<descriptive_name>.md`
- Log clearly where tasks are being created (US folder vs. root Tasks folder)

As a Senior Software Engineer expert in Full Stack development, generate comprehensive implementation tasks based on the provided input. This unified command handles all task generation scenarios with consistent quality and thorough research approach.

## Core Execution Principles

*** MANDATORY VALIDATIONS ***
- **FIRST**: Detect input type and attempt US ID extraction using patterns defined above
- **VALIDATE**: Check if extracted ID is valid (US_XXX format with 3-digit numeric)
- **DECIDE**: If valid US ID ‚Üí create `/Context/Tasks/US_<ID>/` folder; else ‚Üí use `/Context/Tasks/`
- **LOG**: Clearly indicate task placement decision ("Creating tasks in US_XXX folder" or "No US ID found, using root /Context/Tasks/")
- Understanding the input, design documents, and existing codebase is required before task creation
- If source code is missing, prioritize project creation tasks first
- Continue execution if Design.md is unavailable (optional for user stories)
- Think deeply and keep thinking about the implementation ‚Äî think longer to analyze approach comprehensively before proceeding
- Request explicit user confirmation (YES/NO) before writing/updating task files
- **NEVER mark todo items as completed [X] during generation** - all checkboxes must be unchecked `[ ]`
- Update existing files incrementally; avoid unnecessary complete overwrites
- Split tasks exceeding 6 hours into smaller, independently testable units
- Split tasks by technology stack when applicable (separate tasks for frontend, backend, database, etc.)
- Map one task to one requirement/story only ‚Äî NO cross-referencing multiple items
- Single requirements can spawn multiple task files when complexity demands it

## AI Agent Context Strategy

The AI agent receives only your research findings and training data. Since agents have codebase access and equivalent knowledge cutoff, embed comprehensive research findings in the framework. Agents have web search capabilities ‚Äî provide specific documentation URLs and implementation examples.

## Deep Research Methodology

Optimize for success probability over execution speed. Spawn multiple agents and subagents using batch tools for comprehensive analysis.

### 1. Codebase Intelligence Gathering (Sequential Thinking)
- **Design Reference Analysis**: Read `Context/Docs/DesignReference.md` to extract design context for relevant user stories (UI tasks only)
- **User Story Design Mapping**: Identify which user stories this task relates to and extract their design references
- **Visual Asset Loading**: Load Figma URLs OR design images referenced in DesignReference.md for this task's user stories
- **Pattern Discovery**: Search for similar features/implementations in existing codebase
- **Impact Analysis**: Identify existing features requiring modification to maintain functionality
- **Reference Mapping**: Document files and patterns to reference in task design
- **Convention Documentation**: Catalog existing code styles, naming patterns, and architectural approaches
- **Test Pattern Analysis**: Review testing strategies and validation approaches used in the project

### 2. External Knowledge Acquisition
- **Implementation Research**: Search for similar features/patterns in open-source projects
- **Sample Code**: Use `mcp__context7__get-library-docs` for technology-specific, version-specific documentation, code examples, design principles and coding standards
- **Version Pinning**: Use `mcp__context7__resolve-library-id` to pin exact framework/library versions referenced in the task (e.g., .NET 8, EF Core 8, React 19, Python) so subsequent docs/examples are version-accurate.
- **Design Asset Integration**: Reference Figma links OR design images in task context (only when UI impact exists)
- **UI Implementation Guidance**: Include specific design specifications from visual assets (Figma frames OR image files)
- **Component Mapping**: Map design components to code implementation patterns
- **Visual Validation Criteria**: Define pixel-perfect implementation requirements using available design references
- **Style Guidelines**: Research project-specific or framework coding standards
- **Documentation Deep-Dive**: Library documentation with specific section URLs
- **Example Collection**: GitHub repositories, StackOverflow solutions, technical blog implementations
- **Best Practice Synthesis**: Industry patterns, performance considerations, and common pitfalls

### 3. Contextual Clarification (When Needed)
- **Pattern Alignment**: Which existing implementations should be mirrored and their locations?
- **Integration Requirements**: How should new features integrate with existing systems?
- **Quality Standards**: What testing, documentation, and validation standards apply?

## Essential Project Intelligence

### Reference Materials Analysis
- **Gotchas Repository**: Examine `\References\Gotchas` for technology-specific guidelines, anti-patterns, and implementation warnings
- **Codebase Structure**: Explore `app`, `backend`, `server` folders for existing code patterns and architectural decisions
- **Documentation Review**: Study existing README files, API documentation, and inline code comments

*** Codebase comprehension is non-negotiable for quality task generation ***

## Task Design Framework

### Template Foundation
Base all tasks on `References/Templates/task_base.md` structure for consistency.
Integrate design context from `References/Templates/design_reference_base.md` for UI tasks only.

### Critical Context Integration
Package comprehensive context for AI agent success:

**üìö Documentation Context**
- Specific URLs with relevant sections highlighted
- API documentation with version-specific considerations
- Framework guides with implementation examples

**üèóÔ∏è Architecture Context**
- System design patterns and their rationale
- Integration points and data flow diagrams  
- Performance and scalability considerations

**üíª Implementation Context**
- Real code snippets from existing codebase
- Configuration examples and environment setup
- Error handling patterns used in the project

**üé® Design Context (UI Impact Only)**
- **Design Reference Source**: Context/Docs/DesignReference.md#US-XXX (extracted for this task's user stories)
- **Visual References**: Figma URLs OR design images loaded from DesignReference.md
- **Design System Tokens**: Colors, typography, spacing extracted from design reference document
- **Component Specifications**: Visual asset references from DesignReference.md sections
- **Interaction Patterns**: Animation requirements from design reference document
- **Responsive Design**: Breakpoints and behaviors from DesignReference.md

**üì∏ Visual Assets (Loaded from DesignReference.md)**
- **Screenshot References**: UI validation assets from Context/Design/US-XXX/ folders
- **Component Documentation**: Visual specs from DesignReference.md component mappings
- **Design-to-Code Mapping**: Guidelines extracted from design reference document
- **Pixel-Perfect Requirements**: Implementation criteria from DesignReference.md validation sections

**Example Task Design Reference**:
```yaml
Design Context:
  source_document: Context/Docs/DesignReference.md#US-001
  user_story: US-001 - User Login Interface
  visual_references:
    figma_url: https://figma.com/file/xyz?node-id=2:45
    # OR design_images: Context/Design/US-001/login_mockup.png
  design_tokens:
    primary_color: "#007AFF"
    typography: "SF Pro Display, 32px, 600"
  validation_criteria:
    screenshot_comparison: true
    pixel_tolerance: 5%
    responsive_breakpoints: [375px, 768px, 1440px]
```

**‚ö†Ô∏è Critical Knowledge**
- Library-specific quirks and version compatibility issues
- Known limitations and workaround strategies
- Security considerations and compliance requirements

**üîÑ Pattern Consistency**
- Existing approaches for similar functionality
- Naming conventions and code organization patterns
- Testing and validation strategies already established

### Implementation Blueprint Architecture

**Pseudocode Foundation**
- Start with high-level algorithmic approach
- Break down complex operations into manageable steps
- Reference real files demonstrating similar patterns

**Error Resilience Strategy**  
- Identify potential failure points and mitigation approaches
- Document rollback procedures for destructive operations
- Plan validation checkpoints throughout implementation

**Version Pinning** 
- Use `mcp__context7__resolve-library-id` to pin exact framework/library versions referenced in the task (e.g., .NET 8, EF Core 8, React 19, Python, Java) so subsequent docs/examples are version-accurate.


**Sequential Task Breakdown**
- List implementation tasks in logical dependency order
- Include mandatory unit test creation/updates for each component
- Define clear completion criteria and validation gates

**Versioned Doc Excerpts** 
- Include excerpts/links retrieved via `mcp__context7__get-library-docs` (tied to IDs from `resolve-library-id`) for patterns the task expects (validation, transactions, async I/O, HTTP semantics).


## Context Documentation Requirements

### Essential References Package
- **Technical Documentation**: All URLs, guides, and examples needed for implementation
- **Implementation Examples**: Complex code snippets with explanations and context
- **Integration Points**: How the feature connects with existing systems
- **Quality Gates**: Testing requirements, performance benchmarks, security validations

## Output Specifications

### File Organization Strategy:
**For User Story Tasks (US ID found in input):**
- **Directory**: `/Context/Tasks/US_<ID>/`
- **File Pattern**: `task_<seqnum>_<descriptive_name>.md`
- **Example**: `/Context/Tasks/US_001/task_001_implement_login_ui.md`
- **Trigger**: Valid US_XXX pattern extracted from file path, URL, or text content

**For General Tasks (no US ID found - fallback):**
- **Directory**: `/Context/Tasks/`
- **File Pattern**: `task_<seqnum>_<descriptive_name>.md`
- **Example**: `/Context/Tasks/task_001_setup_database.md`
- **Trigger**: No valid US ID extractable from input ‚Üí automatic fallback to root folder

**Fallback Behavior:**
- When US ID cannot be extracted ‚Üí default to `/Context/Tasks/`
- No forced generation of US IDs when not present in input
- Clear logging of task placement decision and reasoning
- Maintain consistent numbering within chosen directory structure

**Sequence Number Logic**:
- Auto-increment based on existing task files in the target directory
- Use zero-padded 3-digit format (001, 002, 003...)
- Separate sequence per US_<ID> folder
- Descriptive name should reflect primary functionality being implemented

## Directory Management

### US ID Extraction Priority
1. **Parse Input**: Attempt to extract US_XXX from input using patterns defined above
2. **Validate Format**: Check if extracted ID matches US_XXX pattern (3-digit numeric)
3. **Fallback to Root**: If no valid US ID found ‚Üí use `/Context/Tasks/` directly

### Directory Creation Logic
**With Valid US ID Found**:
- **Directory**: `/Context/Tasks/US_<ID>/`
- **File Pattern**: `task_<seqnum>_<descriptive_name>.md`
- **Sequence**: Continue from highest existing task number in US folder
- **Example**: `/Context/Tasks/US_001/task_001_implement_login_form.md`

**Without Valid US ID (Fallback)**:
- **Directory**: `/Context/Tasks/`
- **File Pattern**: `task_<seqnum>_<descriptive_name>.md`
- **Sequence**: Continue from highest existing task number in root Tasks folder
- **Example**: `/Context/Tasks/task_001_setup_database.md`

### Task Organization Examples
```
Context/Tasks/
‚îú‚îÄ‚îÄ US_001/ (US ID extracted from input)
‚îÇ   ‚îú‚îÄ‚îÄ US_001.md (user story)
‚îÇ   ‚îú‚îÄ‚îÄ task_001_implement_login_form.md
‚îÇ   ‚îú‚îÄ‚îÄ task_002_add_validation_logic.md
‚îÇ   ‚îî‚îÄ‚îÄ task_003_create_unit_tests.md
‚îú‚îÄ‚îÄ US_002/ (US ID found in URL content)
‚îÇ   ‚îú‚îÄ‚îÄ US_002.md
‚îÇ   ‚îî‚îÄ‚îÄ task_001_setup_password_reset.md
‚îú‚îÄ‚îÄ task_001_general_setup.md (no US ID - fallback)
‚îú‚îÄ‚îÄ task_002_oauth_integration.md (no US ID - fallback)
‚îî‚îÄ‚îÄ task_003_database_migration.md (no US ID - fallback)
```

### Logging and Transparency
- **Always log** the decision: "Creating tasks in US_XXX folder" or "No US ID found, creating tasks in root /Context/Tasks/"
- **Document reasoning** for task placement in task files
- **Maintain clear traceability** between input type and output location

## Quality Assurance Framework

### Pre-Delivery Checklist
- [ ] **User Story Validation**: Parent user story identified and referenced correctly
- [ ] **Folder Structure**: Tasks created in correct US_XXX folder when applicable
- [ ] **Task Numbering**: Sequential numbering within US folder maintained
- [ ] **Acceptance Mapping**: Tasks map to user story acceptance criteria
- [ ] **Story Traceability**: Each task references parent US_XXX appropriately
- [ ] **Context7 References**: Version-pinned docs (IDs + links) are included for all critical patterns the task requires.
- [ ] **Sequential Plan Checklist**: A traceability-friendly checklist derived via `mcp__sequential_thinking__plan` is embedded for execution/analysis.
- [ ] **Design Reference Loaded**: Context/Docs/DesignReference.md read and design context extracted (UI tasks only)
- [ ] **User Story Design Mapping**: Task linked to specific user story design sections from DesignReference.md
- [ ] **Visual Assets Referenced**: Figma URLs OR design images loaded from DesignReference.md (UI tasks only)
- [ ] **Design Tokens Extracted**: Colors, typography, spacing from DesignReference.md included in task
- [ ] **Component Mapping**: Design components from DesignReference.md mapped to code implementations
- [ ] **Validation Criteria Defined**: Pixel-perfect requirements from DesignReference.md included
- [ ] **Context Completeness**: All necessary implementation context included and accessible
- [ ] **Task Scope Validation**: Tasks are under 6 hours and properly split by technology stack when applicable
- [ ] **Technology Stack Separation**: Frontend, backend, database, and infrastructure tasks are independently manageable
- [ ] **Validation Executability**: All quality gates can be executed by AI without human intervention
- [ ] **Pattern Consistency**: References and follows established project patterns
- [ ] **Implementation Clarity**: Clear, unambiguous path from start to completion
- [ ] **Error Handling**: Comprehensive error scenarios documented with responses
- [ ] **Test Strategy**: Testing approach defined with specific validation criteria

## Comprehensive Evaluation Protocol

Score generated tasks using the following metrics (1-100% scale):

### Quality Metrics Assessment

| **Evaluation Dimension** | **Assessment Criteria** |
|---------------------------|-------------------------|
| **Relevance** | Alignment with provided requirements and project context |
| **Correctness** | Technical accuracy and absence of implementation errors |
| **Coherence** | Logical structure, clear progression, and readability |
| **Conciseness** | Optimal information density without unnecessary verbosity |
| **Completeness** | Comprehensive coverage of all implementation aspects |
| **Factual Accuracy** | Verifiable statements and reliable technical information |
| **Implementation Confidence** | Overall assessment of successful execution probability |
| **Risk Assessment** | Identification of harmful or inappropriate content |

### Evaluation Output Template

```markdown
## Task Quality Assessment

| Metric | Score | Notes |
|--------|-------|-------|
| Relevance (%) | [Score]% | [Specific observations] |
| Correctness (%) | [Score]% | [Technical accuracy notes] |
| Coherence (%) | [Score]% | [Structure and flow assessment] |
| Conciseness (%) | [Score]% | [Information density evaluation] |
| Completeness (%) | [Score]% | [Coverage gap analysis] |
| Factual Accuracy (%) | [Score]% | [Verification notes] |
| Implementation Confidence (%) | [Score]% | [Success probability assessment] |
| Risk Assessment | [Pass/Fail] | [Safety and appropriateness check] |

### Quality Summary
**Strengths**: [Key advantages and well-executed aspects]
**Improvement Areas**: [Specific recommendations for enhancement]
**Implementation Readiness**: [Overall assessment of task readiness for execution]
```

## Input Type Handling

This command processes feature-oriented development tasks:

### üéØ Feature Requirements
- **Source**: `Context/Docs/Spec.md` (mandatory)
- **Design**: `Context/Docs/Design.md` (mandatory)
- **Focus**: New feature implementation with comprehensive planning

### üìù User Stories (Primary Input Type)
- **Source**: User story file path (Context/Tasks/US_XXX/US_XXX.md)
- **URL Source**: Remote user story specification
- **Text Source**: Direct user story in standard format
- **Output**: Tasks generated in /Context/Tasks/US_XXX/ folder
- **Focus**: Story-driven task decomposition with acceptance criteria mapping
- **Task Scope**: Each task ‚â§ 6 hours, split by tech stack
- **Traceability**: All tasks reference parent US_XXX


### üìã Functional Specifications
- **Source**: Any text-based functional description
- **Design**: Available project documentation
- **Focus**: Specification-driven implementation with detailed requirements analysis

## Example Usage

### User Story Task Generation (US ID Found)
```bash
# User story file input (US ID extracted from path)
/generate-task Context/Tasks/US_001/US_001.md
# ‚Üí Creates: /Context/Tasks/US_001/task_001_implement_login_form.md

# User story URL with US ID in path
/generate-task https://docs.company.com/stories/US_042/requirements
# ‚Üí Extracts US_042, Creates: /Context/Tasks/US_042/task_001_*.md

# URL with US ID in content (fetches and parses)
/generate-task https://jira.company.com/browse/STORY-15
# ‚Üí Fetches content, finds "US_015" in body
# ‚Üí Creates: /Context/Tasks/US_015/task_001_*.md

# Direct user story text with US ID
/generate-task "US_003: As a user, I want to log in with email and password"
# ‚Üí Extracts US_003, Creates: /Context/Tasks/US_003/task_001_*.md
```

### General Task Generation (No US ID - Fallback)
```bash
# Feature requirements without US ID
/generate-task Context/Docs/Spec.md
# ‚Üí No US ID found, Creates: /Context/Tasks/task_001_setup_authentication.md

# Direct text without US reference
/generate-task "Implement password reset feature"
# ‚Üí No US ID found, Creates: /Context/Tasks/task_001_password_reset.md

# URL without US ID in path or content
/generate-task https://docs.company.com/features/oauth-integration
# ‚Üí Fetches content, no US ID found
# ‚Üí Creates: /Context/Tasks/task_001_oauth_integration.md
```

**Task Output Decision Matrix:**
| Input Type | US ID Found | Output Location | Example |
|------------|-------------|-----------------|---------|
| File path | Yes | `/Context/Tasks/US_XXX/` | `US_001/task_001_*.md` |
| File path | No | `/Context/Tasks/` | `task_001_*.md` |
| URL | Yes | `/Context/Tasks/US_XXX/` | `US_042/task_001_*.md` |
| URL | No | `/Context/Tasks/` | `task_001_*.md` |
| Text | Yes | `/Context/Tasks/US_XXX/` | `US_003/task_001_*.md` |
| Text | No | `/Context/Tasks/` | `task_001_*.md` |

---

*This unified task generator ensures consistent, high-quality task creation across all development scenarios while optimizing for prompt caching and maintainability.*